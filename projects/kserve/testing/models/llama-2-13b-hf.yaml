extends: base
secret_key: "Llama-2-13b-hf"

serving_runtime:
  transformer:
    resource_request:
      cpu: 4
      memory: 8 # in Gi
    extra_env:
      RUNTIME_GRPC_SERVER_THREAD_POOL_SIZE: 160
  kserve:
    resource_request:
      cpu: 4
      memory: 40 # in Gi
      nvidia.com/gpu: 2
      nvidia.com/gpu_memory: 80 # in Gi of GPU memory
    extra_env:
      NUM_GPUS: 2
      FLASH_ATTENTION: true
      DEPLOYMENT_FRAMEWORK: hf_custom_tp
inference_service:
  storage_uri: "s3://psap-watsonx-models/Llama-2-13b-hf/Llama-2-13b-hf"
