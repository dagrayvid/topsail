extends: base
secret_key: "Llama-2-70b-hf"

serving_runtime:
  transformer:
    resource_request:
      cpu: 4
      memory: 8 # in Gi
    extra_env:
      RUNTIME_GRPC_SERVER_THREAD_POOL_SIZE: 160
  kserve:
    resource_request:
      cpu: 8
      memory: 150 # in Gi
      nvidia.com/gpu: 8
    extra_env:
      NUM_GPUS: 8
      FLASH_ATTENTION: true
      DEPLOYMENT_FRAMEWORK: hf_custom_tp
inference_service:
  storage_uri: "s3://psap-watsonx-models/Llama-2-70b-hf/Llama-2-70b-hf"
